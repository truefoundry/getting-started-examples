{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service deployment using TrueFoundry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRhpN7is8PhA"
   },
   "source": [
    "##### This notebook demonstrates a demo of how you can deploy your first service with TrueFoundry.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUqbnAknyr57"
   },
   "source": [
    "After you complete the guide, you will have a successfully deployed model. Your deployed API will look like this:\n",
    "\n",
    "![](https://files.readme.io/e1affc0-Screenshot_2022-11-11_at_5.07.48_PM.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkJQLuPP0Vta"
   },
   "source": [
    "## Project structure\n",
    "\n",
    "To complete this guide, you are going to create the following **files**:\n",
    "\n",
    "- `app.py` : contains our inference and FastAPI code\n",
    "- `iris_classifier.joblib` : the model file\n",
    "- `deploy.py`: contains our deployment code\n",
    "- `requirements.txt` : contains our dependencies\n",
    "\n",
    "Your **final file structure** is going to look like this:\n",
    "\n",
    "```\n",
    ".\n",
    "├── app.py\n",
    "├── iris_classifier.joblib\n",
    "├── deploy.py\n",
    "└── requirements.txt\n",
    "```\n",
    "\n",
    "As you can see, all the following files are created in the same folder/directory\n",
    "\n",
    "**Let's create the directory which will contain all this files:-**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNRHZkr90mLf",
    "outputId": "8ada3cf3-38c4-4d51-8e2b-d2aebd3e0233"
   },
   "outputs": [],
   "source": [
    "%mkdir develop\n",
    "%cd develop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfEqLC9b0cMY"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Let's first setup all the things we need to deploy our service.\n",
    "\n",
    "- Signup or Login on TrueFoundry\n",
    "- Setup Workspace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4d_6OnQ2R6e"
   },
   "source": [
    "Let's start with installing truefoundry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Y8lgCr9Pwzuw",
    "outputId": "ac0e9102-1649-4357-c059-6cf928110ce0"
   },
   "outputs": [],
   "source": [
    "%pip install -U \"truefoundry[ml]>=0.2.0,<1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Login into TrueFoundry**\n",
    "\n",
    "In order to login run the cell below. Host can be found from the TrueFoundry UI as shown below like https://app.truefoundry.com\n",
    "\n",
    "![image.png](../common/images/host.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkXbOJVv8eNE"
   },
   "outputs": [],
   "source": [
    "!tfy login --host \"<Host name of TrueFoundry UI. e.g. https://company.truefoundry.cloud>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wov-JTue8gEF"
   },
   "source": [
    "**Select the `Workspace` in which you want to deploy your application.**\n",
    "\n",
    "Once you run the cell below you will get a prompt to enter your Workspace FQN. Follow the docs to\n",
    "\n",
    "**Create a Workspace**: https://docs.truefoundry.com/docs/key-concepts#creating-a-workspace  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XP_ib5m48k7a"
   },
   "outputs": [],
   "source": [
    "WORKSPACE_FQN = input(\"Enter your Workspace FQN: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n41XXaJD25fM",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 1: Fetch model\n",
    "\n",
    "## Model details\n",
    "\n",
    "For this guide, we have already trained a model.  \n",
    "The given model has been trained on _iris dataset_. Then it is stored as a joblib file in [google drive](https://drive.google.com/file/d/1-9nwjs6F7cp_AhAlBAWZHMXG8yb2q_LR/view).\n",
    "\n",
    "> **Attributes** :  \n",
    "> sepal length in cm, sepal width in cm, petal length in cm, petal width in cm\n",
    ">\n",
    "> **Predicted Attribute** :  \n",
    "> class of iris plant (one of the following - Iris Setosa, Iris Versicolour, Iris Virginica)\n",
    "\n",
    "## Download instructions\n",
    "\n",
    "Download the model from the following [link](https://drive.google.com/file/d/1-9nwjs6F7cp_AhAlBAWZHMXG8yb2q_LR/view).  \n",
    "Then move the model in your dev directory we created.\n",
    "\n",
    "Afterwards, your directory should look like this :\n",
    "\n",
    "```\n",
    ".\n",
    "└── iris_classifier.joblib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmy0aNHS3nnQ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 2: Implement the Inference Service code.\n",
    "\n",
    "The first step is to create a web API and deploy the model.  \n",
    "For this we are going to use [FastAPI](https://fastapi.tiangolo.com/) for this. FastAPI is a modern, intuitive web framework for building web APIs in python.\n",
    "\n",
    "Create the `app.py` and `requirements.txt` files in the same directory where the model is stored.\n",
    "\n",
    "```\n",
    ".\n",
    "├── iris_classifier.joblib\n",
    "├── app.py\n",
    "└── requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2BrljaTI8ugP"
   },
   "source": [
    "### **`app.py`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUqqXRVeyAdt",
    "outputId": "fe7b2dc2-a494-4e29-c5ea-65c7d9b88acb"
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI\n",
    "\n",
    "model = joblib.load(\"iris_classifier.joblib\")\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(\n",
    "    sepal_length: float, sepal_width: float, petal_length: float, petal_width: float\n",
    "):\n",
    "    data = dict(\n",
    "        sepal_length=sepal_length,\n",
    "        sepal_width=sepal_width,\n",
    "        petal_length=petal_length,\n",
    "        petal_width=petal_width,\n",
    "    )\n",
    "    prediction = int(model.predict(pd.DataFrame([data]))[0])\n",
    "    return {\"prediction\": prediction}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zYON72f3ydW"
   },
   "source": [
    "Click on this [link](https://docs.truefoundry.com/recipes/create-a-fastapi-service-code-to-deploy-model) to understand the **`app.py`**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "fastapi==0.81.0\n",
    "uvicorn==0.18.3\n",
    "scikit-learn==1.2.2\n",
    "joblib==1.3.2\n",
    "pandas==2.1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2Q926YI4Yan",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Step 3: Deploying the Inference App\n",
    "\n",
    "You can deploy services on TrueFoundry programmatically via our **Python SDK**.\n",
    "\n",
    "Create a `deploy.py`, after which our file structure will look like this:\n",
    "\n",
    "**File Structure**\n",
    "\n",
    "```Text Text\n",
    ".\n",
    "├── iris_classifier.joblib\n",
    "├── app.py\n",
    "├── deploy.py\n",
    "└── requirements.txt\n",
    "```\n",
    "\n",
    "### **`deploy.py`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pqgBDBmyAX1",
    "outputId": "d59b16ed-4e72-4094-f0c4-d1e802088c8b"
   },
   "outputs": [],
   "source": [
    "%%writefile deploy.py\n",
    "import argparse\n",
    "import logging\n",
    "from truefoundry.deploy import Build, PythonBuild, Service, Resources, Port, LocalSource\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--name\", required=True, type=str, help=\"Name of the application.\")\n",
    "parser.add_argument(\n",
    "    \"--workspace_fqn\",\n",
    "    required=True,\n",
    "    type=str,\n",
    "    help=\"FQN of the workspace where application will be deployed.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--host\",\n",
    "    required=True,\n",
    "    type=str,\n",
    "    help=\"Host where the application will be available for access. Ex:- my-app.my-org.com\",\n",
    ")\n",
    "args = parser.parse_args()\n",
    "\n",
    "image = Build(\n",
    "    build_source=LocalSource(local_build=False),\n",
    "    build_spec=PythonBuild(\n",
    "        python_version=\"3.11\",\n",
    "        command=\"uvicorn app:app --port 8000 --host 0.0.0.0\",\n",
    "        requirements_path=\"requirements.txt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "service = Service(\n",
    "    name=args.name,\n",
    "    image=image,\n",
    "    ports=[Port(port=8000, host=args.host)],\n",
    "    resources=Resources(\n",
    "        cpu_request=0.1,\n",
    "        cpu_limit=0.1,\n",
    "        memory_request=500,\n",
    "        memory_limit=500,\n",
    "    ),\n",
    "    env={\"UVICORN_WEB_CONCURRENCY\": \"1\", \"ENVIRONMENT\": \"dev\"},\n",
    ")\n",
    "service.deploy(workspace_fqn=args.workspace_fqn, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I61_mM7Y447C"
   },
   "source": [
    "Click on this [link](https://docs.truefoundry.com/recipes/deploy-fastapi-service-via-python) to understand the **`deploy.py`**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_NAME = input(\"Enter the Service name\")\n",
    "SERVICE_HOST = input(\n",
    "    \"Enter the Service Host (Can be found from cluster details in TrueFoundry UI)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ex8BEPH5OY5"
   },
   "source": [
    "Now to deploy our FastAPI Service run the command below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMYgmbFk5Jd0",
    "outputId": "c6a1212b-7096-44f3-ea4e-d75565ca4e0f"
   },
   "outputs": [],
   "source": [
    "!python deploy.py --name $SERVICE_NAME --workspace_fqn $WORKSPACE_FQN --host $SERVICE_HOST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the build is complete, you will see a link to the dashboard after a message like <br>\n",
    "`You can find the application on the dashboard:-`.\n",
    "\n",
    "Click on the link to access the deployment dashboard.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
